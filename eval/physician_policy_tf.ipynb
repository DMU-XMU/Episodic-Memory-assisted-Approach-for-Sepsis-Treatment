{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn the physician policy - ie, pi(a|s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data_o/rl_train_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('../data_o/rl_val_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data_o/rl_test_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (state vector) and labels (action taken) out of the dataframe for train \n",
    "# and val sets\n",
    "def preproc(df_in, iv_bins = 5):\n",
    "    df = df_in.copy()\n",
    "    actions_raw = df[['iv_input', 'vaso_input']].values\n",
    "    keep_arr = np.loadtxt('../data/state_features.txt', dtype=str)\n",
    "    df = df[keep_arr]\n",
    "    actions_proc = (iv_bins*actions_raw[:, 0] + actions_raw[:, 1]).astype(int)\n",
    "    #hist = np.histogram(actions_proc, 25)\n",
    "    actions_proc = pd.get_dummies(actions_proc).values\n",
    "    #print(hist) \n",
    "    return df.values, actions_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_sample(batch_size, features, labels):\n",
    "    idx = np.random.choice(np.arange(len(features)), batch_size)\n",
    "    return (np.vstack(features[idx]), np.vstack(labels[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat, train_labels = preproc(train_data)\n",
    "val_feat, val_labels = preproc(val_data)\n",
    "test_feat, test_labels = preproc(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_length = len(train_feat[0])\n",
    "batch_size = 64\n",
    "num_actions = 25\n",
    "num_steps = 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo - reduce network size\n",
    "class PolicyModel():\n",
    "    def __init__(self):\n",
    "        self.input_feat = tf.placeholder(tf.float32, shape = [None, feature_length])\n",
    "        self.labels = tf.placeholder(tf.float32, shape = [None, num_actions])\n",
    "        self.phase = tf.placeholder(tf.bool)\n",
    "        \n",
    "        self.fc_1 = tf.contrib.layers.fully_connected(self.input_feat, 64, activation_fn=tf.nn.relu) #64\n",
    "        self.bn_1 = tf.contrib.layers.batch_norm(self.fc_1, center=True, scale=True, is_training=self.phase)\n",
    "#         self.fc_2 = tf.contrib.layers.fully_connected(self.bn_1 , 256, activation_fn=tf.nn.relu)    \n",
    "#         self.bn_2 = tf.contrib.layers.batch_norm(self.fc_2 , center=True, scale=True, is_training=self.phase)\n",
    "#         L2_drop_2 = tf.nn.dropout(self.bn_2,0.8)\n",
    "#         self.fc_3 = tf.contrib.layers.fully_connected(L2_drop_2, 128, activation_fn=tf.nn.relu)\n",
    "#         self.bn_3 = tf.contrib.layers.batch_norm(self.fc_3, center=True, scale=True, is_training=self.phase)\n",
    "#         L2_drop_3 = tf.nn.dropout(self.fc_3,0.8)\n",
    "        self.fc_4 = tf.contrib.layers.fully_connected(self.bn_1 , 64, activation_fn=tf.nn.relu) #64\n",
    "        self.bn_4 = tf.contrib.layers.batch_norm(self.fc_4, center=True, scale=True, is_training=self.phase)\n",
    "        \n",
    "        self.logits = tf.contrib.layers.fully_connected(self.bn_4 , num_actions, activation_fn=None)\n",
    "        self.output = tf.nn.softmax(self.logits)\n",
    "        self.reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        self.reg_constant = 0.1 \n",
    "        \n",
    "        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(self.labels, 1), tf.argmax(self.output, 1)),'float32'))\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.logits, labels = self.labels)) + self.reg_constant*sum(self.reg_losses)\n",
    "\n",
    "        \n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(self.update_ops):\n",
    "            self.train_step = tf.train.AdamOptimizer().minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints out accuracy on the relevant dataset and returns the policy. \n",
    "# This is the probability of taking each action in the action space from that state\n",
    "\n",
    "def get_policy(dataset,sess, mdl):\n",
    "\n",
    "    if dataset == 'train':\n",
    "        features, labels = train_feat,train_labels\n",
    "    elif dataset == 'val':\n",
    "        features, labels = val_feat,val_labels\n",
    "    elif dataset == 'test':\n",
    "        features, labels = test_feat,test_labels\n",
    "\n",
    "    \n",
    "    op = np.zeros((len(features), num_actions))\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    j = 0\n",
    "    while (j < len(features)):\n",
    "        feat = None\n",
    "        lbls = None\n",
    "        if len(features) - j < batch_size:\n",
    "            feat = features[j:-1]\n",
    "            lbls = labels[j:-1]\n",
    "        else:\n",
    "            feat = features[j:j+batch_size]\n",
    "            lbls = labels[j:j+batch_size]\n",
    "        feat = feat.reshape(len(feat), feature_length)\n",
    "        lbls = lbls.reshape(len(lbls), num_actions)\n",
    "        if j%10000 == 0: print('Processing val set indx: ', j )\n",
    "        softmax, accuracy, loss = sess.run([mdl.output, mdl.accuracy, mdl.loss], feed_dict={mdl.input_feat : feat, mdl.phase: 0, mdl.labels: lbls, mdl.phase: 0})\n",
    "        total_acc += accuracy\n",
    "        op[j:j+len(feat)] = softmax\n",
    "        if len(features) - j < batch_size:\n",
    "            j = len(features)\n",
    "        else: j+=batch_size\n",
    "        final_acc = total_acc/(len(op)/batch_size)\n",
    "        total_loss += loss\n",
    "    return op, final_acc, total_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    tf.reset_default_graph()\n",
    "    mdl = PolicyModel()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # Don't use all GPUs \n",
    "    config.allow_soft_placement = True  # Enable manual control\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init)\n",
    "        net_loss = 0\n",
    "        net_accuracy = 0.0\n",
    "        print('Starting training!')\n",
    "        for i in range(num_steps):\n",
    "            feat, labels = batch_sample(batch_size, train_feat, train_labels)\n",
    "            \n",
    "            _, loss, accuracy = sess.run([mdl.train_step, mdl.loss, mdl.accuracy], feed_dict={mdl.input_feat : feat, mdl.labels: labels, mdl.phase: 1})\n",
    "            \n",
    "            net_loss += loss\n",
    "            net_accuracy += accuracy\n",
    "            if i % 1000 == 0 and i > 0:\n",
    "                av_loss = net_loss/1000.0\n",
    "                av_accuracy = net_accuracy/1000.0\n",
    "                print(\"Step: \", i, \"Average loss is: \", av_loss, \"Average accuracy is: \", av_accuracy)\n",
    "                net_loss = 0.0\n",
    "                net_accuracy = 0.0\n",
    "            \n",
    "            if i % 10000 == 0:\n",
    "                print (\"Test on validation set\")\n",
    "                _, val_acc, val_loss = get_policy('val', sess, mdl)\n",
    "                print('Val set accuracy, loss: ', val_acc, val_loss)\n",
    "                \n",
    "        # Commented out for now\n",
    "        # train_policy, train_acc = get_policy('train')\n",
    "        print (\"Finished, getting final accuracy\")\n",
    "        val_policy, val_acc, val_loss = get_policy('val', sess, mdl)\n",
    "        test_policy, test_acc, _ = get_policy('test',sess, mdl)\n",
    "    print('Val set accuracy, loss: ', val_acc, val_loss)\n",
    "    print('Test set accuracy: ', test_acc)\n",
    "\n",
    "    return val_policy, test_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_24580/990086361.py:2: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_24580/4166246858.py:4: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_24580/4166246858.py:21: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_24580/4166246858.py:21: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_24580/4166246858.py:25: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_24580/4166246858.py:30: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_24580/990086361.py:4: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_24580/990086361.py:7: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_24580/990086361.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Starting training!\n",
      "Test on validation set\n",
      "Processing val set indx:  0\n",
      "Val set accuracy, loss:  0.004026893898536656 1447.8720092773438\n",
      "Step:  1000 Average loss is:  2.004774188041687 Average accuracy is:  0.33409375\n",
      "Step:  2000 Average loss is:  1.7374808579683303 Average accuracy is:  0.359015625\n",
      "Step:  3000 Average loss is:  1.7111755373477935 Average accuracy is:  0.36778125\n",
      "Step:  4000 Average loss is:  1.7014298932552339 Average accuracy is:  0.36809375\n",
      "Step:  5000 Average loss is:  1.6760490601062774 Average accuracy is:  0.37534375\n",
      "Step:  6000 Average loss is:  1.6670990616083146 Average accuracy is:  0.37646875\n",
      "Step:  7000 Average loss is:  1.6532194664478301 Average accuracy is:  0.377734375\n",
      "Step:  8000 Average loss is:  1.64392345559597 Average accuracy is:  0.3785\n",
      "Step:  9000 Average loss is:  1.638147385597229 Average accuracy is:  0.381375\n",
      "Step:  10000 Average loss is:  1.6305998873710632 Average accuracy is:  0.38109375\n",
      "Test on validation set\n",
      "Processing val set indx:  0\n",
      "Val set accuracy, loss:  0.34022459522469917 774.9100867509842\n",
      "Step:  11000 Average loss is:  1.6259497094154358 Average accuracy is:  0.382078125\n",
      "Step:  12000 Average loss is:  1.624804348707199 Average accuracy is:  0.384765625\n",
      "Step:  13000 Average loss is:  1.6202029629945756 Average accuracy is:  0.380515625\n",
      "Step:  14000 Average loss is:  1.6181401003599167 Average accuracy is:  0.38234375\n",
      "Step:  15000 Average loss is:  1.614452602624893 Average accuracy is:  0.38528125\n",
      "Step:  16000 Average loss is:  1.6115143764019013 Average accuracy is:  0.385\n",
      "Step:  17000 Average loss is:  1.6042898195981978 Average accuracy is:  0.38634375\n",
      "Step:  18000 Average loss is:  1.6053570498228074 Average accuracy is:  0.3865625\n",
      "Step:  19000 Average loss is:  1.5973712385892869 Average accuracy is:  0.386890625\n",
      "Step:  20000 Average loss is:  1.5993889220952988 Average accuracy is:  0.3905\n",
      "Test on validation set\n",
      "Processing val set indx:  0\n",
      "Val set accuracy, loss:  0.3588050352229667 756.2120628356934\n",
      "Step:  21000 Average loss is:  1.5994482610225678 Average accuracy is:  0.38825\n",
      "Step:  22000 Average loss is:  1.5946556524038316 Average accuracy is:  0.389796875\n",
      "Step:  23000 Average loss is:  1.590571583867073 Average accuracy is:  0.39015625\n",
      "Step:  24000 Average loss is:  1.5878305059671403 Average accuracy is:  0.391484375\n",
      "Step:  25000 Average loss is:  1.598310094356537 Average accuracy is:  0.388171875\n",
      "Step:  26000 Average loss is:  1.586538949728012 Average accuracy is:  0.39025\n",
      "Step:  27000 Average loss is:  1.582411918282509 Average accuracy is:  0.38909375\n",
      "Step:  28000 Average loss is:  1.5766972937583923 Average accuracy is:  0.391265625\n",
      "Step:  29000 Average loss is:  1.5867811279296875 Average accuracy is:  0.390890625\n",
      "Step:  30000 Average loss is:  1.5796982024908066 Average accuracy is:  0.391453125\n",
      "Test on validation set\n",
      "Processing val set indx:  0\n",
      "Val set accuracy, loss:  0.35562906233370206 770.4347225427628\n",
      "Step:  31000 Average loss is:  1.5789275722503662 Average accuracy is:  0.39071875\n",
      "Step:  32000 Average loss is:  1.5807938126325607 Average accuracy is:  0.392234375\n",
      "Step:  33000 Average loss is:  1.5785240226984023 Average accuracy is:  0.39234375\n",
      "Step:  34000 Average loss is:  1.5770892767906188 Average accuracy is:  0.392421875\n",
      "Step:  35000 Average loss is:  1.5767452632188796 Average accuracy is:  0.3920625\n",
      "Step:  36000 Average loss is:  1.5738122645616532 Average accuracy is:  0.391953125\n",
      "Step:  37000 Average loss is:  1.5725885217189788 Average accuracy is:  0.394890625\n",
      "Step:  38000 Average loss is:  1.5685992014408112 Average accuracy is:  0.39315625\n",
      "Step:  39000 Average loss is:  1.5791828734874724 Average accuracy is:  0.3910625\n",
      "Step:  40000 Average loss is:  1.5698896110057832 Average accuracy is:  0.394671875\n",
      "Test on validation set\n",
      "Processing val set indx:  0\n",
      "Val set accuracy, loss:  0.35354370658196144 770.2591134309769\n",
      "Step:  41000 Average loss is:  1.5646944515705108 Average accuracy is:  0.396515625\n",
      "Step:  42000 Average loss is:  1.5653121429681778 Average accuracy is:  0.396796875\n",
      "Step:  43000 Average loss is:  1.5648424572944641 Average accuracy is:  0.39640625\n",
      "Step:  44000 Average loss is:  1.565809664607048 Average accuracy is:  0.395078125\n",
      "Step:  45000 Average loss is:  1.5609762365818023 Average accuracy is:  0.39525\n",
      "Step:  46000 Average loss is:  1.569800612092018 Average accuracy is:  0.391890625\n",
      "Step:  47000 Average loss is:  1.5639775229692459 Average accuracy is:  0.395578125\n",
      "Step:  48000 Average loss is:  1.5582884126901626 Average accuracy is:  0.396890625\n",
      "Step:  49000 Average loss is:  1.5637848349809647 Average accuracy is:  0.393703125\n",
      "Step:  50000 Average loss is:  1.564845973610878 Average accuracy is:  0.3945625\n",
      "Test on validation set\n",
      "Processing val set indx:  0\n",
      "Val set accuracy, loss:  0.3614936260859377 774.8430889844894\n",
      "Step:  51000 Average loss is:  1.5638931523561477 Average accuracy is:  0.395609375\n",
      "Step:  52000 Average loss is:  1.5582870316505433 Average accuracy is:  0.396015625\n",
      "Step:  53000 Average loss is:  1.5610467382669448 Average accuracy is:  0.3981875\n",
      "Step:  54000 Average loss is:  1.5597514386177063 Average accuracy is:  0.395265625\n",
      "Step:  55000 Average loss is:  1.5618558294773102 Average accuracy is:  0.394734375\n",
      "Step:  56000 Average loss is:  1.5602979481220245 Average accuracy is:  0.395046875\n",
      "Step:  57000 Average loss is:  1.5602813301086427 Average accuracy is:  0.39675\n",
      "Step:  58000 Average loss is:  1.555481117129326 Average accuracy is:  0.39928125\n",
      "Step:  59000 Average loss is:  1.554539458155632 Average accuracy is:  0.397125\n",
      "Step:  60000 Average loss is:  1.5565635858774185 Average accuracy is:  0.397671875\n",
      "Test on validation set\n",
      "Processing val set indx:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set accuracy, loss:  0.3655724541395951 732.9982464313507\n",
      "Step:  61000 Average loss is:  1.5576342287063598 Average accuracy is:  0.395046875\n",
      "Step:  62000 Average loss is:  1.5581345125436783 Average accuracy is:  0.3981875\n",
      "Step:  63000 Average loss is:  1.5548220794200898 Average accuracy is:  0.400296875\n",
      "Step:  64000 Average loss is:  1.5554102017879485 Average accuracy is:  0.3971875\n",
      "Step:  65000 Average loss is:  1.5535350737571716 Average accuracy is:  0.397796875\n",
      "Step:  66000 Average loss is:  1.5564927599430085 Average accuracy is:  0.39540625\n",
      "Step:  67000 Average loss is:  1.5572698106765748 Average accuracy is:  0.398078125\n",
      "Step:  68000 Average loss is:  1.5583278810977936 Average accuracy is:  0.395484375\n",
      "Step:  69000 Average loss is:  1.5498424896001817 Average accuracy is:  0.39925\n",
      "Finished, getting final accuracy\n",
      "Processing val set indx:  0\n",
      "Processing val set indx:  0\n",
      "Processing val set indx:  40000\n",
      "Val set accuracy, loss:  0.3707858435618077 710.6563432216644\n",
      "Test set accuracy:  0.3781954680065402\n"
     ]
    }
   ],
   "source": [
    "val_policy, test_policy = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save the learned policy as a numpy array with the columns as icustayid, bloc, iv input, vaso input,\n",
    "#  action index (of 25), and probability distribution over actions ( this is 25 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_data = val_data[['icustayid', 'bloc', 'iv_input', 'vaso_input']].values\n",
    "val_actions = (5*val_data['iv_input'].values + val_data['vaso_input']).values.astype(int)\n",
    "val_pickle = np.concatenate((v_data, val_actions.reshape(len(val_actions), 1), val_policy), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = test_data[['icustayid', 'bloc', 'iv_input', 'vaso_input']].values\n",
    "test_actions = (5*test_data['iv_input'].values + test_data['vaso_input']).values.astype(int)\n",
    "test_pickle = np.concatenate((t_data, test_actions.reshape(len(test_actions), 1), test_policy), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"val_policy.p\", \"wb\") as f:\n",
    "    pickle.dump(val_pickle, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"test_policy.p\", \"wb\") as f:\n",
    "    pickle.dump(test_pickle, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
