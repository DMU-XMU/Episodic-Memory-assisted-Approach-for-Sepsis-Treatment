{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import  pickle\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albumin', 'Arterial_BE', 'Arterial_lactate', 'Arterial_pH', 'BUN', 'CO2_mEqL', 'Calcium', 'Chloride', 'Creatinine', 'DiaBP', 'FiO2_1', 'GCS', 'Glucose', 'HCO3', 'HR', 'Hb', 'INR', 'Ionised_Ca', 'Magnesium', 'MeanBP', 'PT', 'PTT', 'PaO2_FiO2', 'Platelets_count', 'Potassium', 'RR', 'SGOT', 'SGPT', 'SIRS', 'SOFA', 'Shock_Index', 'Sodium', 'SpO2', 'SysBP', 'Temp_C', 'Total_bili', 'WBC_count', 'Weight_kg', 'age', 'elixhauser', 'gender', 'mechvent', 'output_4hourly', 'output_total', 'paCO2', 'paO2', 're_admission', 'bloc']\n"
     ]
    }
   ],
   "source": [
    "with open('../data/state_features.txt') as f:\n",
    "    state_features = f.read().split()\n",
    "print (state_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rl_train_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloc</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>elixhauser</th>\n",
       "      <th>re_admission</th>\n",
       "      <th>died_in_hosp</th>\n",
       "      <th>died_within_48h_of_out_time</th>\n",
       "      <th>mortality_90d</th>\n",
       "      <th>...</th>\n",
       "      <th>input_total</th>\n",
       "      <th>input_4hourly</th>\n",
       "      <th>output_total</th>\n",
       "      <th>output_4hourly</th>\n",
       "      <th>cumulated_balance</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>SIRS</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>6898241400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902327</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223817</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.222560</td>\n",
       "      <td>11</td>\n",
       "      <td>6898255800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902327</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.574861</td>\n",
       "      <td>0.707254</td>\n",
       "      <td>0.223281</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.546041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.356608</td>\n",
       "      <td>11</td>\n",
       "      <td>6898270200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902327</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629131</td>\n",
       "      <td>0.723746</td>\n",
       "      <td>0.222629</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.884898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452837</td>\n",
       "      <td>11</td>\n",
       "      <td>6898284600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902327</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.659814</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.221953</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.527957</td>\n",
       "      <td>11</td>\n",
       "      <td>6898299000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902327</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675701</td>\n",
       "      <td>0.699627</td>\n",
       "      <td>0.221464</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bloc  icustayid   charttime  gender       age  elixhauser  \\\n",
       "0  0.000000         11  6898241400     1.0  0.902327    0.428571   \n",
       "1  0.222560         11  6898255800     1.0  0.902327    0.428571   \n",
       "2  0.356608         11  6898270200     1.0  0.902327    0.428571   \n",
       "3  0.452837         11  6898284600     1.0  0.902327    0.428571   \n",
       "4  0.527957         11  6898299000     1.0  0.902327    0.428571   \n",
       "\n",
       "   re_admission  died_in_hosp  died_within_48h_of_out_time  mortality_90d  \\\n",
       "0           1.0             0                            0              0   \n",
       "1           1.0             0                            0              0   \n",
       "2           1.0             0                            0              0   \n",
       "3           1.0             0                            0              0   \n",
       "4           1.0             0                            0              0   \n",
       "\n",
       "   ...  input_total  input_4hourly  output_total  output_4hourly  \\\n",
       "0  ...          0.0            0.0      0.000000        0.000000   \n",
       "1  ...          0.0            0.0      0.574861        0.707254   \n",
       "2  ...          0.0            0.0      0.629131        0.723746   \n",
       "3  ...          0.0            0.0      0.659814        0.726688   \n",
       "4  ...          0.0            0.0      0.675701        0.699627   \n",
       "\n",
       "   cumulated_balance      SOFA  SIRS  vaso_input  iv_input    reward  \n",
       "0           0.223817  0.500000  0.00         0.0       0.0  0.383136  \n",
       "1           0.223281  0.416667  0.00         0.0       0.0 -0.546041  \n",
       "2           0.222629  0.416667  0.25         0.0       0.0 -0.884898  \n",
       "3           0.221953  0.458333  0.25         0.0       0.0 -0.025000  \n",
       "4           0.221464  0.458333  0.25         0.0       0.0  0.125000  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('../data/rl_val_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/rl_test_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an action mapping - how to get an id representing the action from the (iv,vaso) tuple\n",
    "action_map = {}\n",
    "count = 0\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_map[(iv,vaso)] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_action_map = {}\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        inv_action_map[5*iv+vaso] = [iv,vaso]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the actions from the q network\n",
    "q_net_save_dir = '../continuous/dqn_normalT/'\n",
    "train_actions = pickle.load(open( q_net_save_dir + \"dqn_normal_actions_train.p\", \"rb\" ))\n",
    "val_actions = pickle.load(open( q_net_save_dir + \"dqn_normal_actions_val.p\", \"rb\" ))\n",
    "test_actions = pickle.load(open( q_net_save_dir + \"dqn_normal_actions_test.p\", \"rb\" ))\n",
    "\n",
    "df['agent_actions'] = train_actions\n",
    "df['agent_iv'] = df['agent_actions'].apply(lambda x:inv_action_map[x][0] )\n",
    "df['agent_vaso'] = df['agent_actions'].apply(lambda x:inv_action_map[x][1] )\n",
    "\n",
    "val_df['agent_actions'] = val_actions\n",
    "val_df['agent_iv'] = val_df['agent_actions'].apply(lambda x:inv_action_map[x][0] )\n",
    "val_df['agent_vaso'] = val_df['agent_actions'].apply(lambda x:inv_action_map[x][1] )\n",
    "\n",
    "test_df['agent_actions'] = test_actions\n",
    "test_df['agent_iv'] = test_df['agent_actions'].apply(lambda x:inv_action_map[x][0] )\n",
    "test_df['agent_vaso'] = test_df['agent_actions'].apply(lambda x:inv_action_map[x][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the actions so that they are zero mean\n",
    "df['iv_input'] = df['iv_input'].apply(lambda x: x/4.0)\n",
    "df['vaso_input'] = df['vaso_input'].apply(lambda x: x/4.0)\n",
    "\n",
    "val_df['iv_input'] = val_df['iv_input'].apply(lambda x: x/4.0)\n",
    "val_df['vaso_input'] = val_df['vaso_input'].apply(lambda x: x/4.0)\n",
    "\n",
    "test_df['iv_input'] = test_df['iv_input'].apply(lambda x: x/4.0)\n",
    "test_df['vaso_input'] = test_df['vaso_input'].apply(lambda x: x/4.0)\n",
    "\n",
    "df['agent_iv'] = df['agent_iv'].apply(lambda x: x/4.0)\n",
    "df['agent_vaso'] = df['agent_vaso'].apply(lambda x: x/4.0)\n",
    "\n",
    "val_df['agent_iv'] = val_df['agent_iv'].apply(lambda x: x/4.0)\n",
    "val_df['agent_vaso'] = val_df['agent_vaso'].apply(lambda x: x/4.0)\n",
    "\n",
    "test_df['agent_iv'] = test_df['agent_iv'].apply(lambda x: x/4.0)\n",
    "test_df['agent_vaso'] = test_df['agent_vaso'].apply(lambda x: x/4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Gaussian noise to the state features\n",
    "gaussian_shape = df.loc[:, state_features].values.shape\n",
    "noise = np.random.normal(0, 0.03, gaussian_shape)\n",
    "df.loc[:, state_features] += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_1_size = 500\n",
    "hidden_2_size = 500\n",
    "class EnvModel():\n",
    "    def __init__(self):\n",
    "        self.phase = tf.placeholder(tf.bool)\n",
    "        \n",
    "        self.input_size = len(state_features)\n",
    "\n",
    "        self.cur_state = tf.placeholder(tf.float32, shape=[None, self.input_size],name=\"cur_state\")\n",
    "        self.next_state = tf.placeholder(tf.float32, shape=[None, self.input_size],name=\"next_state\")\n",
    "        \n",
    "        self.done_flags = tf.placeholder(tf.int32, shape=[None], name=\"done_flags\")\n",
    "        \n",
    "        self.actions = tf.placeholder(tf.int32, shape = [None, 2], name=\"actions\")\n",
    "        \n",
    "        self.input = tf.concat([self.cur_state, tf.cast(self.actions, tf.float32)], axis=1)\n",
    "        \n",
    "        self.target = self.next_state - self.cur_state\n",
    "\n",
    "        self.fc_1 = tf.contrib.layers.fully_connected(self.input, hidden_1_size, activation_fn=tf.nn.relu)\n",
    "        self.fc_1_bn = tf.contrib.layers.batch_norm(self.fc_1, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_2 = tf.contrib.layers.fully_connected(self.fc_1_bn, hidden_2_size, activation_fn=tf.nn.relu)\n",
    "        self.fc_2_bn = tf.contrib.layers.batch_norm(self.fc_2, center=True, scale=True, is_training=self.phase)\n",
    "        \n",
    "        self.output = tf.contrib.layers.fully_connected(self.fc_2_bn, self.input_size, activation_fn = None)\n",
    "        \n",
    "        self.multiplier = tf.expand_dims(1 -self.done_flags, 1)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.multiply(tf.square(self.target-self.output), tf.cast(self.multiplier, tf.float32)))  \n",
    "        \n",
    "        self.est_next_state = self.output + self.cur_state  #下一个状态 = 预测增量 ＋ 当前状态\n",
    "\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(self.update_ops):\n",
    "        # Ensures that we execute the update_ops before performing the model update, so batchnorm works\n",
    "            self.update_model = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_batch(size):\n",
    "    a = df.sample(n=size)\n",
    "    states = None\n",
    "    actions = None\n",
    "    rewards = None\n",
    "    next_states = None\n",
    "    done_flags = None\n",
    "    for i in a.index:\n",
    "        cur_state = a.loc[i,state_features]\n",
    "        iv = int(a.loc[i, 'iv_input'])\n",
    "        vaso = int(a.loc[i, 'vaso_input'])\n",
    "        action = np.array([iv,vaso])\n",
    "\n",
    "        if i != df.index[-1]:\n",
    "            # if not terminal step in trajectory             \n",
    "            if df.loc[i, 'icustayid'] == df.loc[i+1, 'icustayid']:\n",
    "                next_state = df.loc[i + 1, state_features]\n",
    "                done = 0\n",
    "            else:\n",
    "                # trajectory is finished\n",
    "                next_state = np.zeros(len(cur_state))\n",
    "                done = 1\n",
    "        else:\n",
    "            # last entry in df is the final state of that trajectory\n",
    "            next_state = np.zeros(len(cur_state))\n",
    "            done = 1\n",
    "\n",
    "        if states is None:\n",
    "            states = copy.deepcopy(cur_state)\n",
    "        else:\n",
    "            states = np.vstack((states,cur_state))\n",
    "\n",
    "        if actions is None:\n",
    "            actions = [action]\n",
    "        else:\n",
    "            actions = np.vstack((actions,action))\n",
    "\n",
    "        if next_states is None:\n",
    "            next_states = copy.deepcopy(next_state)\n",
    "        else:\n",
    "            next_states = np.vstack((next_states,next_state))\n",
    "\n",
    "        if done_flags is None:\n",
    "            done_flags = [done]\n",
    "        else:\n",
    "            done_flags = np.vstack((done_flags,done))\n",
    "    \n",
    "    return (states, np.squeeze(actions), next_states, np.squeeze(done_flags), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract chunks of length size from the relevant dataframe, and yield these to the caller\n",
    "# final tells us if we want to use AGENT actions, not physician actions\n",
    "def process_eval_batch(size, eval_type = None, final=False):\n",
    "    if eval_type is None:\n",
    "        raise Exception('Provide eval_type to process_eval_batch')\n",
    "    elif eval_type == 'train':\n",
    "        a = df.copy()\n",
    "    elif eval_type == 'val':\n",
    "        a = val_df.copy()\n",
    "    elif eval_type == 'test':\n",
    "        a = test_df.copy()\n",
    "    else:\n",
    "        raise Exception('Unknown eval_type')\n",
    "    count = 0\n",
    "    while count < len(a.index):\n",
    "        states = None\n",
    "        actions = None\n",
    "        rewards = None\n",
    "        next_states = None\n",
    "        done_flags = None\n",
    "\n",
    "        start_idx = count\n",
    "        end_idx = min(len(a.index), count+size)\n",
    "        segment = a.index[start_idx:end_idx]\n",
    "        \n",
    "        for i in segment:\n",
    "            cur_state = a.loc[i,state_features]\n",
    "            \n",
    "            if not final:\n",
    "                iv = int(a.loc[i, 'iv_input'])\n",
    "                vaso = int(a.loc[i, 'vaso_input'])\n",
    "                action = np.array([iv,vaso])\n",
    "            else:\n",
    "                iv = int(a.loc[i, 'agent_iv'])\n",
    "                vaso = int(a.loc[i, 'agent_vaso'])\n",
    "                action = np.array([iv,vaso])\n",
    "            reward = a.loc[i,'reward']\n",
    "\n",
    "            if i != a.index[-1]:\n",
    "                # if not terminal step in trajectory             \n",
    "                if a.loc[i, 'icustayid'] == a.loc[i+1, 'icustayid']:\n",
    "                    next_state = a.loc[i + 1, state_features]\n",
    "                    done = 0\n",
    "                else:\n",
    "                    # trajectory is finished\n",
    "                    next_state = np.zeros(len(cur_state))\n",
    "                    done = 1\n",
    "            else:\n",
    "                # last entry in df is the final state of that trajectory\n",
    "                next_state = np.zeros(len(cur_state))\n",
    "                done = 1\n",
    "\n",
    "            if states is None:\n",
    "                states = copy.deepcopy(cur_state)\n",
    "            else:\n",
    "                states = np.vstack((states,cur_state))\n",
    "\n",
    "            if actions is None:\n",
    "                actions = [action]\n",
    "            else:\n",
    "                actions = np.vstack((actions,action))\n",
    "\n",
    "            if next_states is None:\n",
    "                next_states = copy.deepcopy(next_state)\n",
    "            else:\n",
    "                next_states = np.vstack((next_states,next_state))\n",
    "\n",
    "            if done_flags is None:\n",
    "                done_flags = [done]\n",
    "            else:\n",
    "                done_flags = np.vstack((done_flags,done))\n",
    "\n",
    "        yield (states, np.squeeze(actions), next_states, np.squeeze(done_flags), a)\n",
    "        \n",
    "        count += size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_eval(eval_type, final=False):\n",
    "    gen = process_eval_batch(size = 1000, eval_type=eval_type, final=final)\n",
    "\n",
    "    error_ret = 0\n",
    "    est_next_states = []\n",
    "\n",
    "    for b in gen:\n",
    "\n",
    "        states,actions,next_states, done_flags, _ = b\n",
    "\n",
    "        est_next_state,loss = sess.run([env_model.est_next_state,env_model.loss], \\\n",
    "            feed_dict={env_model.cur_state:states,\n",
    "                       env_model.next_state:next_states, \n",
    "                       env_model.actions:actions,\n",
    "                       env_model.done_flags:done_flags,\n",
    "                       env_model.phase:False})    \n",
    "        error_ret += loss\n",
    "        est_next_states.append(est_next_state)\n",
    "  \n",
    "    return np.array(est_next_states), error_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # Don't use all GPUs \n",
    "config.allow_soft_placement = True  # Enable manual control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_save_results():\n",
    "    # get the estimated next states UNDER THE AGENT POLICY based on the trained environment model\n",
    "    est_next_states_train, _ = do_eval(eval_type = 'train', final=True)        \n",
    "    est_next_states_val, _ = do_eval(eval_type = 'val', final=True)        \n",
    "    est_next_states_test, _ = do_eval(eval_type = 'test', final=True)   \n",
    "    \n",
    "    # save everything for later - they're used in policy evaluation and when generating plots\n",
    "    with open(save_dir + 'est_next_states_train.p', 'wb') as f:\n",
    "        pickle.dump(est_next_states_train, f)\n",
    "    with open(save_dir + 'est_next_states_val.p', 'wb') as f:\n",
    "        pickle.dump(est_next_states_val, f)\n",
    "    with open(save_dir + 'est_next_states_test.p', 'wb') as f:\n",
    "        pickle.dump(est_next_states_test, f)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load model...\n",
      "INFO:tensorflow:Restoring parameters from ./env_model_regression/ckpt\n",
      "Model restored\n",
      "Init done\n",
      "Saved Model, step is 1000\n",
      "Average loss is  0.00021866526066878579\n",
      "Saved Model, step is 2000\n",
      "Average loss is  0.00021756604203255846\n",
      "Saved Model, step is 3000\n",
      "Average loss is  0.00021872609859565273\n",
      "Saved Model, step is 4000\n",
      "Average loss is  0.0002195398225230747\n",
      "Saved Model, step is 5000\n",
      "Average loss is  0.00021821961348177866\n",
      "Saved Model, step is 6000\n",
      "Average loss is  0.00021728554432775128\n",
      "Saved Model, step is 7000\n",
      "Average loss is  0.00021777011276572013\n",
      "Saved Model, step is 8000\n",
      "Average loss is  0.0002188581334630726\n",
      "Saved Model, step is 9000\n",
      "Average loss is  0.00021779590588266728\n",
      "Saved Model, step is 10000\n",
      "Average loss is  0.00021749177171295742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1693765469826758\n",
      "Saved Model, step is 11000\n",
      "Average loss is  0.00021920736598258372\n",
      "Saved Model, step is 12000\n",
      "Average loss is  0.0002200252209586324\n",
      "Saved Model, step is 13000\n",
      "Average loss is  0.00022087058522447477\n",
      "Saved Model, step is 14000\n",
      "Average loss is  0.00021969152831297835\n",
      "Saved Model, step is 15000\n",
      "Average loss is  0.00021973035560222343\n",
      "Saved Model, step is 16000\n",
      "Average loss is  0.000218950066526304\n",
      "Saved Model, step is 17000\n",
      "Average loss is  0.0002172159703623038\n",
      "Saved Model, step is 18000\n",
      "Average loss is  0.00021875704808189765\n",
      "Saved Model, step is 19000\n",
      "Average loss is  0.00021846508974704193\n",
      "Saved Model, step is 20000\n",
      "Average loss is  0.00021955904927744996\n",
      "0.17456511408090591\n",
      "Saved Model, step is 21000\n",
      "Average loss is  0.0002205288192781154\n",
      "Saved Model, step is 22000\n",
      "Average loss is  0.0002190678127662977\n",
      "Saved Model, step is 23000\n",
      "Average loss is  0.00021837765781674534\n",
      "Saved Model, step is 24000\n",
      "Average loss is  0.00021787460328050656\n",
      "Saved Model, step is 25000\n",
      "Average loss is  0.0002172046748601133\n",
      "Saved Model, step is 26000\n",
      "Average loss is  0.00021744018865865655\n",
      "Saved Model, step is 27000\n",
      "Average loss is  0.00021776293712900952\n",
      "Saved Model, step is 28000\n",
      "Average loss is  0.00021729908227280248\n",
      "Saved Model, step is 29000\n",
      "Average loss is  0.00021870178084645885\n",
      "Saved Model, step is 30000\n",
      "Average loss is  0.00021910559690149967\n",
      "0.17864991584792733\n",
      "Saved Model, step is 31000\n",
      "Average loss is  0.00021926000130770263\n",
      "Saved Model, step is 32000\n",
      "Average loss is  0.00021963343208335572\n",
      "Saved Model, step is 33000\n",
      "Average loss is  0.0002182137882045936\n",
      "Saved Model, step is 34000\n",
      "Average loss is  0.00021807201001502107\n",
      "Saved Model, step is 35000\n",
      "Average loss is  0.00022085734717256856\n",
      "Saved Model, step is 36000\n",
      "Average loss is  0.00021925389338139212\n",
      "Saved Model, step is 37000\n",
      "Average loss is  0.00021857289134641177\n",
      "Saved Model, step is 38000\n",
      "Average loss is  0.0002188946324022254\n",
      "Saved Model, step is 39000\n",
      "Average loss is  0.0002179757458216045\n",
      "Saved Model, step is 40000\n",
      "Average loss is  0.0002182340530853253\n",
      "0.16724081290885806\n",
      "Saved Model, step is 41000\n",
      "Average loss is  0.00021752360061509535\n",
      "Saved Model, step is 42000\n",
      "Average loss is  0.0002177968829346355\n",
      "Saved Model, step is 43000\n",
      "Average loss is  0.00021794685220811517\n",
      "Saved Model, step is 44000\n",
      "Average loss is  0.0002182727110630367\n",
      "Saved Model, step is 45000\n",
      "Average loss is  0.00021810654895671177\n",
      "Saved Model, step is 46000\n",
      "Average loss is  0.00021871516141982284\n",
      "Saved Model, step is 47000\n",
      "Average loss is  0.00021914840523095335\n",
      "Saved Model, step is 48000\n",
      "Average loss is  0.0002178532168327365\n",
      "Saved Model, step is 49000\n",
      "Average loss is  0.00021846851302689173\n",
      "Saved Model, step is 50000\n",
      "Average loss is  0.00021801990488893352\n",
      "0.22322943387553096\n",
      "Saved Model, step is 51000\n",
      "Average loss is  0.0002171764390077442\n",
      "Saved Model, step is 52000\n",
      "Average loss is  0.00021876124161644838\n",
      "Saved Model, step is 53000\n",
      "Average loss is  0.00021677859219198581\n",
      "Saved Model, step is 54000\n",
      "Average loss is  0.00021635472355410458\n",
      "Saved Model, step is 55000\n",
      "Average loss is  0.00021846810938586713\n",
      "Saved Model, step is 56000\n",
      "Average loss is  0.00021647815097094282\n",
      "Saved Model, step is 57000\n",
      "Average loss is  0.00021689543980755844\n",
      "Saved Model, step is 58000\n",
      "Average loss is  0.0002182587000352214\n",
      "Saved Model, step is 59000\n",
      "Average loss is  0.0002178351059410488\n"
     ]
    }
   ],
   "source": [
    "# The main training loop is here\n",
    "batch_size = 32\n",
    "num_steps = 60000 # How many steps to train for\n",
    "load_model = True #Whether to load a saved model.\n",
    "save_dir = \"./env_model_regression/\"\n",
    "save_path = \"./env_model_regression/ckpt\"#The path to save our model to.rk\n",
    "tf.reset_default_graph()\n",
    "env_model = EnvModel()\n",
    "save_results = False\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    if load_model == True:\n",
    "        print('Trying to load model...')\n",
    "        try:\n",
    "            restorer = tf.train.import_meta_graph(save_path + '.meta')\n",
    "            restorer.restore(sess, tf.train.latest_checkpoint(save_dir))\n",
    "            print (\"Model restored\")\n",
    "        except IOError:\n",
    "            print (\"No previous model found, running default init\")\n",
    "            sess.run(init)\n",
    "    else:\n",
    "        print(\"Running default init\")\n",
    "        sess.run(init)\n",
    "    print(\"Init done\")\n",
    "    \n",
    "    net_loss = 0.0\n",
    "    for i in range(num_steps):\n",
    "        if save_results:\n",
    "            print (\"Calling do save results\")\n",
    "            do_save_results()\n",
    "            break\n",
    "        \n",
    "        states,actions,next_states, done_flags, sampled_df = process_train_batch(batch_size)\n",
    "\n",
    "        # Train with the batch\n",
    "        _,loss = sess.run([env_model.update_model,env_model.loss], \\\n",
    "            feed_dict={env_model.cur_state:states,\n",
    "                       env_model.next_state:next_states, \n",
    "                       env_model.actions:actions,\n",
    "                       env_model.done_flags:done_flags,\n",
    "                       env_model.phase:True})\n",
    "\n",
    "        net_loss += loss\n",
    "    \n",
    "        \n",
    "        if i % 1000 == 0 and i > 0:\n",
    "            saver.save(sess,save_path)\n",
    "            print(\"Saved Model, step is \" + str(i))\n",
    "            \n",
    "            av_loss = net_loss/(1000.0 * batch_size)\n",
    "            print(\"Average loss is \", av_loss)\n",
    "            net_loss = 0.0\n",
    "        \n",
    "        if (i % 10000==0) and i > 0:\n",
    "            # run an evaluation on the validation set\n",
    "            _, error = do_eval(eval_type = 'val')        \n",
    "            print (error)\n",
    "#             if (i % 30000==0) and i > 0:\n",
    "#                 print (\"Saving results\")\n",
    "#                 do_save_results()\n",
    "    do_save_results()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
